## 基于深度学习的深度估计

### Part 1 前期基础论文

+ 1. 2014 NIPS [Depth Map Prediction from a Single Image using a Multi-Scale Deep Network](http://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1406.2283.pdf) 第一篇CNN-based来做的单目估计深度的论文

这里的Multi-scale不是现在网络中Multi-scale features的做法，而是分为两个scale的网络来做DepthMap的估计，分别是Global Coarse-Scale Network和Local Fine-Scale Network。前者其实就是AlexNet，来得到一个低分辨率的Coarse的Depth Map,再用后者去refine前者的输出得到最后的refined depth map

代码：<https://github.com/hjimce/Depth-Map-Prediction>

+ 2. 2015 ICCV 也是上一篇的作者David Eigen发的 [Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture](https://arxiv.org/pdf/1411.4734.pdf)　

可以预测出Depth, Normals, Labels

+ 3. 2016 IEEE 3D Vision [Deeper Depth Prediction with Fully Convolutional Residual Networks](https://arxiv.org/pdf/1606.00373.pdf) **FCRN**

这是一个比较经典的用神经网络估计深度的算法，可以好好了解下

代码：<https://github.com/iro-cp/FCRN-DepthPrediction>　

### Part 2  state-of-art
自己看过跑过代码效果比较好，可以借鉴的论文，有监督，无监督，自监督，耦合几何信息（SLAM），sparse to dense 等等，可以从有无利用几何信息粗略的分为两大类

#### 没有利用几何信息：

+ 前面part 1 的所有算法

+ 2018 MIT **sparse-to-dense :** 有监督学习，采用单张RGB和稀疏深度图来直接估计单目稠密深度图，探索了深度样本的数量对估计精度的影响。

  paper：Sparse-to-Dense: Depth Prediction from Sparse Depth Samples and a Single Image](https://arxiv.org/pdf/1709.07492.pdf

  code：https://github.com/fangchangma/sparse-to-dense.pytorch

+ 2019 CVPR **DenseDepth**：虽然是没有耦合几何信息的有监督学习，但是最后的效果超出很多结合深度学习的深度估计算法。应该是用到了迁移学习（ImageNet在DenseNet上训练的权重来初始化encoder部分），ImageNet的海量图片和DenseNet在图像特征表达上的优越性，使得网络从RGB图像特征到深度信息的学习更加准确，同时边缘也比较清晰，泛化能力也不错。虽然没有用到几何信息，是ill-posed问题，但是可以类比人类仅适用一只眼也可以知道所处场景大概的深度情况。关于loss的设计也值得借鉴，采用三部分加权求和的loss，三部分分别为，单像素loss、梯度loss、SSIMloss。

  paper： [Dense Depth:High Quality Monocular Depth Estumation via Transfer Learning](https://arxiv.org/pdf/1812.11941.pdf)

  code： https://github.com/ialhashim/DenseDepth

#### 利用几何信息：

+ ～～题外话～～

  **关于深度学习结合SLAM**：深度学习结合SLAM是近几年比较热的一个研究方向，和单目深度估计就是其中的一个小方向。但是在SLAM中很多部分都是相互耦合的比如位姿估计和深度估计，以及特征提取匹配等，因此充分熟悉SLAM算法和深度学习框架的优缺点，才能更好的将两者结合起来。以下是一些现有的两者结合的研究方向，或许可以互为启发。

  + 用深度学习替换传统SLAM中的模块：

    + 特征提取: 2016 ECCV [LIFT: Learned Invariant Feature Transform](https://arxiv.org/abs/1603.09114)

    + 深度估计

    + 位姿估计: deep learning 和SLAM 结合的开山之作，2015 ICCV **PoseNet**：

      paper：[PoseNet: A Convolutional Network for Real-Time 6-DOF Camera Relocalization](<https://arxiv.org/abs/1505.07427>) 

      code： https://github.com/alexgkendall/caffe-posenet

    + 其他

  + SLAM + 语义信息：

    + 语义地图构建

  + 端到端的SLAM：image到action

    + 机器人自主导航（深度强化学习）

+ 深度学习+几何信息的深度估计：总体框架都为encoder-decoder结构


  1. 2018 HKUST **MVDepthNet**  [MVDepthNet: Real-time Multiview Depth Estimation Neural Network](https://arxiv.org/abs/1807.08563)

输入reference image 和一序列source images 计算cost volume(采用**DTAM**中关于cost volume 的构建方式)　几何和深度学习的图像feature是分离的

笔记：[MVDepthNet_FCRN](./MVDepthNet_FCRN/MVDepthNet.pdf)    
[cost volume in MVDepthNet](./MVDepthNet_costVolume/DTAM中cost_volume的含义.pdf)  
[densedepth_MVDepthNet_MVSNet](./densedepth_MVDepthNet_MVSNet/depth_prediction.pdf)  

  2. 2018 HKUST ECCV **MVSNet** [MVSNet: Depth Inference for Unstructured Multi-view Stereo](https://arxiv.org/abs/1804.02505)

还是港科大做的，这个算法将几何信息和神经网络输出耦合在一起，将神经网络得到的特征图计算homogarphy，由此构造一个cost volume，与MVDepthNet的区别是这里将深度学习学到的特特征和几何信息紧耦合在一起，前者只是将几何中原本要计算的优化作为训练过程的一个约束，都是有监督的算法。加了一个深度概率图模块。

笔记：[MVSNet](https://blog.csdn.net/john_xia/article/details/88100410)

code：[MVSNet](./mvsnet_aitsim)

3. 2019 HKUST [Recurrent MVSNet for High-resolution Multi-view Stereo Depth Inference](<https://arxiv.org/abs/1902.10556>) 

解决了上一版本训练时的内存消耗问题，添加GRU 单元降低内存消耗，同时提高了输出深度图的分辨率。还有新出的**Point-MVSNet**

4. 2018 CVPR **RNN-SLAM** [Recurrent Neural Network for Learning DenseDepth and Ego-Motion from Video](<https://arxiv.org/abs/1805.06558v1>)

无监督有监督都可以实现（有监督信息来自colmap的稀疏深度），采用LSTM模块，利用时间序列信息，可以同时估计depth（网络输出disparity  depth = disparity/focal_length*baseline）和pose（重投影误差） 缺点：输入图像之间的baseline采用一个值（整个数据集均值）最后depth的准确性与baseline关系较大。

code：[RNN_depth_pose](./RNN_depth_pose)  

5. 除此之外经典的算法还有：**sfm-Learner**、**Geo-Net**、**DeMon**  等但是和前面三种方法思想大同小异，有监督、无监督、深耦合SLAM信息和深度学习、松耦合、利用时间序列信息、光流、视差、等等，均达不到传统算法的准确性。

##  SfM

+ 特征点提取与特征点匹配

  + 特征点提取
  + 特征点匹配

+ 基础矩阵估计 F

  + 五点法
  + 八点法
    + RANSAC

+ 本质矩阵估计 E

+ 本质矩阵分解为R和T

  + SVD分解
  
+ 三维点云计算

  + 三角形法
+ 重投影
  + 将三维点三角化并重映射到摄像机得到二维点，计算与最初二维点之间的距离，重投影误差
